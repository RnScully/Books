{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import pprint\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "#from Scraper import gr_db_cleaner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "client = MongoClient('localhost', 27017)\n",
    "db=client['reviews']\n",
    "coll=db['user_reviews']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".find() creates a \"cursor\" which pulls the data. .limit() keeps you from pulling all the data. Wrapping the \"cursor\" in a list comprehension builds that cursor out iteratively into a list containing the things you want to manipulate. Ok? Cool. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [x for x in coll.find().limit(1000)]\n",
    "test[0]['userid']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now, its more complicated than that, because all of this is nested *again* So in the cursor list? you've got a dictonary that holds user_id and a list of reviews. so index into 'reviews' and you get to a list of your actual scraped bits, the data from goodreads. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = test[3]['reviews']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you're going to want to make those giant strings of html into a handle-able-able object. So put it in a bowl with beatiful soup. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'review' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-69ab689e2eff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'html.parser'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'review' is not defined"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(review, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author = soup.find_all(class_ = re.compile('author'))[0].text.strip('author ').split('\\n')[0]\n",
    "author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_type =soup.find_all(class_ = re.compile('format'))[0].text.split('\\n')[1].strip()\n",
    "book_type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isbn = int(soup.find_all(class_ = re.compile('isbn13'))[0].text.strip('isbn13').strip())\n",
    "isbn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = soup.find_all(class_ = re.compile('title'))[0].text.split('\\n')[1].strip()\n",
    "title\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "title = soup.find_all(class_ = re.compile('title'))[0].text\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = int(soup.find_all(class_ =re.compile('num_pages'))[0].text.split()[2])\n",
    "pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "av_rate = float(soup.find_all(class_ =re.compile('avg_rating'))[0].text.split()[2])\n",
    "av_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rate = int(soup.find_all(class_ =re.compile('num_ratings'))[0].text.split()[2].replace(',',''))\n",
    "num_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_rate(qual_state):\n",
    "    '''\n",
    "    a function that turns goodreads's \"I liked it\" or \"I did not like it\" star categories\n",
    "    into the numerical 1-5 rating that they visually imply. \n",
    "    ++++++\n",
    "    Attributes\n",
    "    qual_state (list) a split string pulled from the beautiful soup output of .text on the rating object\n",
    "    ++++++\n",
    "    Returns\n",
    "    user_rating (int): 1-5 score based on NUMBER OF STARS SELECTED BY THE RATER. I honestly don't understand why that's not the output in the HTML. \n",
    "    '''\n",
    "    if qual_state[-3:] == ['it', 'was', 'amazing']:\n",
    "        user_rating = 5\n",
    "    elif qual_state[-3:] ==['really','liked','it']:\n",
    "        user_rating = 4\n",
    "    elif qual_state[-2:] ==['liked', 'it']:\n",
    "        '''note that I belive any that include \"really\" will be given 4\n",
    "        before we get to this elif statement, therefore we don't need \n",
    "        to worry about the issues of \"really liked it\" and \"liked it\"\n",
    "        overlapping'''\n",
    "        user_rating= 3\n",
    "    elif qual_state[-3:]==['it','was','ok']:\n",
    "        user_rating = 2\n",
    "    elif qual_state[-3:]==['not','like','it']:\n",
    "        user_rating = 1\n",
    "    else:\n",
    "        user_rating = 0\n",
    "    return user_rating\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_rating = str_to_rate(soup.find_all(class_ =re.compile('field rating'))[0].text.split())\n",
    "user_rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Putting it all together**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaner(find_lim = 10):\n",
    "    '''\n",
    "    a function that reads in goodreads user review tables gathered\n",
    "    by the gr_scraper and returns a list for schema\n",
    "    +++++++++++\n",
    "    Atributes\n",
    "    find_lim (int): how many user-reviews to clean. pass 'all' into find lim\n",
    "                    to clean entire db.   \n",
    "    +++++++\n",
    "    '''\n",
    "   \n",
    "\n",
    "    client = MongoClient('localhost', 27017)\n",
    "    db=client['reviews']\n",
    "    collection=db['user_reviews']\n",
    "    \n",
    "\n",
    "\n",
    "    documents = [x for x in db['user_reviews'].find().limit(find_lim)]\n",
    "    client.close()\n",
    "    all_revs = []\n",
    "    for idx, users in enumerate(documents):\n",
    "        try:\n",
    "            user = documents[idx]['userid']\n",
    "        except:\n",
    "            continue\n",
    "       \n",
    "        review_list = documents[idx]['reviews']\n",
    "        if len(review_list) ==0: #some users have not added any books to their goodreads profile\n",
    "            sub_rev = [None, None, None, None, None, user, None, None, None]\n",
    "            all_revs.append(sub_rev)\n",
    "        else:\n",
    "            for review in review_list:\n",
    "                soup = BeautifulSoup(review, 'html.parser')\n",
    "                title = soup.find_all(class_ = re.compile('title'))[0].text.split('\\n')[1].strip()\n",
    "                try:\n",
    "                    pages = int(soup.find_all(class_ =re.compile('num_pages'))[0].text.split()[2])\n",
    "                except:#Some works are infinite scroll documents without pages. \n",
    "                    pages = None\n",
    "                try:\n",
    "                    isbn = soup.find_all(class_ = re.compile('isbn13'))[0].text.strip('isbn13').strip()\n",
    "                except: #some works are not given ISBN\n",
    "                    isbn = None \n",
    "                book_type = soup.find_all(class_ = re.compile('format'))[0].text.split('\\n')[0].strip()\n",
    "                author = soup.find_all(class_ = re.compile('author'))[0].text.strip('author ').split('\\n')[0]\n",
    "                av_rate = float(soup.find_all(class_ =re.compile('avg_rating'))[0].text.split()[2])\n",
    "                num_rate = int(soup.find_all(class_ =re.compile('num_ratings'))[0].text.split()[2].replace(',',''))\n",
    "                user_rating = str_to_rate(soup.find_all(class_ =re.compile('field rating'))[0].text.split())\n",
    "                \n",
    "                sub_rev = [title,author, isbn, book_type, pages, user, user_rating, num_rate, av_rate]\n",
    "                all_revs.append(sub_rev)\n",
    "    return all_revs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "documents[1405].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = cleaner()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"datacln\", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data, columns = ['title','author', 'isbn', 'book_type', 'pages', 'userid', 'user_rating', 'num_rate', 'av_rate'])  \n",
    "\n",
    "#get rid of any users who haven't added any books, and any added books with no user rating\n",
    "dfwr = df.dropna(axis=0)\n",
    "actually_rated = dfwr['user_rating'] != 0\n",
    "dfwr = dfwr[actually_rated]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 38 entries, 2 to 44\n",
      "Data columns (total 9 columns):\n",
      "title          38 non-null object\n",
      "author         38 non-null object\n",
      "isbn           38 non-null object\n",
      "book_type      38 non-null object\n",
      "pages          38 non-null float64\n",
      "userid         38 non-null int64\n",
      "user_rating    38 non-null float64\n",
      "num_rate       38 non-null float64\n",
      "av_rate        38 non-null float64\n",
      "dtypes: float64(4), int64(1), object(4)\n",
      "memory usage: 3.0+ KB\n"
     ]
    }
   ],
   "source": [
    "dfwr.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfwr['av_rate'].hist(bins = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfwr['user_rating'].hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its pretty clear, from these histograms, that at least in the initial thousand user-reviews sampled in my dataset, that goodreads reviews are heavily weighted towards the high end of the scale. lets do a simple hypothesis test and see where we stand against statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample is all of our user ratings, sampling was done as part of the scraping randomized list operation\n",
    "sample =dfwr['user_rating']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Book readers tend to be saps, correct? \n",
    "so our hypothesis is that the average rating of books by users of goodreads is higher than 4 out of 5 stars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Null Hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graph the null hypothesis\n",
    "\n",
    "null_hyp = stats.norm.rvs(loc=4, scale=np.std(sample)/np.sqrt(len(sample)), size=len(sample), random_state=None)\n",
    "fig, ax = plt.subplots(1,2, figsize = (30,15))\n",
    "\n",
    "ax[0] = plt.hist(null_hyp, color = 'g', bins = 20, alpha = .7, label = 'null hypothesis')\n",
    "\n",
    "#ax[1] = plt.hist(sample, color = 'c', bins = 5, alpha = .4, label ='sample')\n",
    "\n",
    "#fig.set_title ('sampled ratings against hypothesised ratings')\n",
    "#ax[0].set_ylabel('nuber of ratings')\n",
    "#ax[0].set_xlabel('rating score')\n",
    "\n",
    "#ax[0].legend(loc='upper left', frameon = False)\n",
    "#fig.xlabel('number of ratings')\n",
    "plt.show()\n",
    "\n",
    "#fig.savefig('img/hypothesis_test', dpi = 300, bbox_inches = 'tight', transparent = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_1samp(sample, 4, axis=0, nan_policy='propagate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph the sample and the hypothesis(a uniform distribution of the same size as the sample)\n",
    "null_hyp = stats.uniform.rvs(loc=0, scale=5, size=len(sample), random_state=None)\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax = plt.hist(null_hyp, color = 'g', bins = 5, alpha = .7, label = 'null hypothesis')\n",
    "ax = sample.hist(color = 'c', bins = 5, alpha = .0, label ='sample')\n",
    "\n",
    "ax.set_title('uniform ratings')\n",
    "ax.set_ylabel('nuber of ratings')\n",
    "ax.set_xlabel(\"the sort of bins we would expect, if people were perfectly rational. Which we're obviously not.\")\n",
    "\n",
    "#ax.legend(loc='upper left', frameon = False)\n",
    "#fig.xlabel('number of ratings')\n",
    "plt.show()\n",
    "\n",
    "#fig.savefig('img/uniform_rational_graph2', dpi = 300, bbox_inches = 'tight', transparent = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph the sample and the hypothesis(a uniform distribution of the same size as the sample)\n",
    "null_hyp = stats.norm.rvs(loc=4, scale=np.std(sample), size=len(sample), random_state=None)\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax = plt.hist(null_hyp, color = 'g', bins = 4, alpha = .7, label = 'null hypothesis')\n",
    "ax = sample.hist(color = 'c', bins = 5, alpha = .7, label ='sample')\n",
    "\n",
    "ax.set_title('sampled ratings against uniform ratings')\n",
    "ax.set_ylabel('nuber of ratings')\n",
    "ax.set_xlabel('rating score')\n",
    "\n",
    "ax.legend(loc='upper left', frameon = False)\n",
    "#fig.xlabel('number of ratings')\n",
    "plt.show()\n",
    "\n",
    "fig.savefig('img/hypothesis_graph', dpi = 300, bbox_inches = 'tight', transparent = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
